{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the ELT process for the CNN Timeline of Key Events related to COVID-19 found here: \n",
    "    \n",
    "    https://dataviz.nbcnews.com/projects/20200302-covid-timeline/index.html?initialWidth=1160&childId=embed-20200302-covid-timeline&parentTitle=Coronavirus%20timeline%3A%20Tracking%20the%20critical%20moments%20of%20Covid-19&parentUrl=https%3A%2F%2Fwww.nbcnews.com%2Fhealth%2Fhealth-news%2Fcoronavirus-timeline-tracking-critical-moments-covid-19-n1154341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "\n",
    "url = 'https://dataviz.nbcnews.com/projects/20200302-covid-timeline/index.html?initialWidth=1160&childId=embed-20200302-covid-timeline&parentTitle=Coronavirus%20timeline%3A%20Tracking%20the%20critical%20moments%20of%20Covid-19&parentUrl=https%3A%2F%2Fwww.nbcnews.com%2Fhealth%2Fhealth-news%2Fcoronavirus-timeline-tracking-critical-moments-covid-19-n1154341'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "\n",
    "soup = bs(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-36c15b22867e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdate_list\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdate_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vt-date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdate_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m', 2020'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: find() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "#Scrape CNN timeline for the key dates and add to a list\n",
    "\n",
    "date_results = soup.find('div', class_='holder-container')\n",
    "\n",
    "\n",
    "date_list =[]\n",
    "for result in date_results:\n",
    "    date = result.find('p', class_='vt-date')\n",
    "    date_list.append(date.text+', 2020')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape CNN timeline for the news stories and add to list\n",
    "\n",
    "news_results = soup.find_all('div', class_='holder-text')\n",
    "\n",
    "news_list=[]\n",
    "for result in news_results:\n",
    "    news = result.find('p', class_='vt-contex')\n",
    "    news_list.append(news.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with date and news story from CNN timeline using pandas\n",
    "#Clean up Dates \n",
    "\n",
    "Timeline_df = pd.DataFrame({\"Date\":date_list, \"News Event\":news_list})\n",
    "Timeline_df.loc[[0], ['Date']]=\"Dec. 31, 2019\"\n",
    "Timeline_df.loc[[1], ['Date']]=\"Jan. 7, 2020\"\n",
    "Timeline_df[\"Date\"] = Timeline_df[\"Date\"].str.replace(\".\",\"\")\n",
    "Timeline_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Date into datetime format\n",
    "\n",
    "Timeline_df['Date_dt']=pd.to_datetime(Timeline_df[\"Date\"], infer_datetime_format=True)\n",
    "Timeline_df = Timeline_df[['Date_dt', 'News Event']]\n",
    "Timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load table into Postgres database\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://cggjytcd:2Lf6GkD0Cb8TbV6e4-X7ZBCvNMh_zV3F@raja.db.elephantsql.com:5432/cggjytcd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timeline_df.to_sql(name='cnn_news', schema='public', con=engine, method='multi', if_exists='replace', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
